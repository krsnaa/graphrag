{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path within the notebook\n",
    "# This will add the parent directory to the Python path, allowing you to import the graphrag package.\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Set up directories\n",
    "root_dir = Path(\"./inputs/hello-graphrag\")\n",
    "input_dir = root_dir / \"input\"\n",
    "output_dir = root_dir / \"output\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "input_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create a sample .txt file if it doesn't exist\n",
    "sample_file = input_dir / \"emf-review.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.aggregate\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.bin\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.binarize\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.boolean\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.concat\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.convert\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.copy\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.dedupe\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.derive\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.destructure\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.difference\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.drop\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.erase\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.fill\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.filter\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.fold\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.groupby\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.impute\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.intersect\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.join\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.lookup\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.merge\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.onehot\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.orderby\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.parallel_verb\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.pivot\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.print\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.recode\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.rename\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.rollup\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.sample\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.select\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.spread\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.strings.lower\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.strings.replace\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.strings.upper\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.types\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.unfold\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.ungroup\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.unhot\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.union\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.unorder\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.unroll\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.utils.merge_utils\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.utils.unhot_utils\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.verb_input\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.verbs_mapping\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.window\n",
      "INFO:datashaper.engine.verbs:Found module: datashaper.engine.verbs.workflow\n",
      "INFO:graphrag.config.read_dotenv:Loading pipeline .env file\n",
      "INFO:graphrag.config.create_graphrag_config:EnvironmentReader\n"
     ]
    }
   ],
   "source": [
    "from graphrag.config import create_graphrag_config\n",
    "from graphrag.config.enums import InputFileType, InputType\n",
    "\n",
    "# Create a basic configuration\n",
    "config = create_graphrag_config(\n",
    "    root_dir=str(root_dir),\n",
    "    values={\n",
    "        \"input\": {\n",
    "            \"type\": InputType.file,\n",
    "            \"file_type\": InputFileType.text,\n",
    "            \"base_dir\": \"input\",\n",
    "            \"file_pattern\": r\".*\\.txt$\",\n",
    "        },\n",
    "        \"storage\": {\"base_dir\": \"output\"},\n",
    "        \"claim_extraction\": {\n",
    "            \"enabled\": True,            \n",
    "        },\n",
    "        # Simplify the pipeline for this test\n",
    "        # skip_workflows=[\n",
    "        #     \"create_final_community_reports\",\n",
    "        #     \"create_final_covariates\",\n",
    "        # ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:graphrag.index.create_pipeline_config:Using LLM Config {\n",
      "    \"api_key\": \"*****\",\n",
      "    \"type\": \"azure_openai_chat\",\n",
      "    \"model\": \"gpt-4-turbo-preview\",\n",
      "    \"max_tokens\": 4000,\n",
      "    \"temperature\": 0.0,\n",
      "    \"top_p\": 1.0,\n",
      "    \"n\": 1,\n",
      "    \"request_timeout\": 180.0,\n",
      "    \"api_base\": \"http://0.0.0.0:8000\",\n",
      "    \"api_version\": \"1978-02-16\",\n",
      "    \"organization\": null,\n",
      "    \"proxy\": null,\n",
      "    \"cognitive_services_endpoint\": null,\n",
      "    \"deployment_name\": \"kiku-deployment\",\n",
      "    \"model_supports_json\": true,\n",
      "    \"tokens_per_minute\": 0,\n",
      "    \"requests_per_minute\": 0,\n",
      "    \"max_retries\": 10,\n",
      "    \"max_retry_wait\": 10.0,\n",
      "    \"sleep_on_rate_limit_recommendation\": true,\n",
      "    \"concurrent_requests\": 25\n",
      "}\n",
      "INFO:graphrag.index.create_pipeline_config:Using Embeddings Config {\n",
      "    \"api_key\": \"*****\",\n",
      "    \"type\": \"openai_embedding\",\n",
      "    \"model\": \"text-embedding-3-small\",\n",
      "    \"max_tokens\": 4000,\n",
      "    \"temperature\": 0,\n",
      "    \"top_p\": 1,\n",
      "    \"n\": 1,\n",
      "    \"request_timeout\": 180.0,\n",
      "    \"api_base\": \"http://0.0.0.0:8000\",\n",
      "    \"api_version\": \"1978-02-16\",\n",
      "    \"organization\": null,\n",
      "    \"proxy\": null,\n",
      "    \"cognitive_services_endpoint\": null,\n",
      "    \"deployment_name\": null,\n",
      "    \"model_supports_json\": null,\n",
      "    \"tokens_per_minute\": 0,\n",
      "    \"requests_per_minute\": 0,\n",
      "    \"max_retries\": 10,\n",
      "    \"max_retry_wait\": 10.0,\n",
      "    \"sleep_on_rate_limit_recommendation\": true,\n",
      "    \"concurrent_requests\": 25\n",
      "}\n",
      "INFO:graphrag.index.create_pipeline_config:skipping workflows \n",
      "INFO:__main__:\n",
      "\n",
      "Initial Workflow order:\n",
      "INFO:__main__:1. create_base_documents\n",
      "INFO:__main__:2. create_final_documents\n",
      "INFO:__main__:3. create_base_text_units\n",
      "INFO:__main__:4. join_text_units_to_entity_ids\n",
      "INFO:__main__:5. join_text_units_to_relationship_ids\n",
      "INFO:__main__:6. join_text_units_to_covariate_ids\n",
      "INFO:__main__:7. create_final_text_units\n",
      "INFO:__main__:8. create_base_extracted_entities\n",
      "INFO:__main__:9. create_summarized_entities\n",
      "INFO:__main__:10. create_base_entity_graph\n",
      "INFO:__main__:11. create_final_entities\n",
      "INFO:__main__:12. create_final_relationships\n",
      "INFO:__main__:13. create_final_nodes\n",
      "INFO:__main__:14. create_final_communities\n",
      "INFO:__main__:15. create_final_community_reports\n",
      "INFO:__main__:16. create_final_covariates\n"
     ]
    }
   ],
   "source": [
    "from graphrag.index import create_pipeline_config\n",
    "\n",
    "# Create the pipeline configuration\n",
    "pipeline_config = create_pipeline_config(config, verbose=True)\n",
    "\n",
    "# Log the initial workflow order\n",
    "logger.info(\"\\n\\nInitial Workflow order:\")\n",
    "for i, workflow in enumerate(pipeline_config.workflows):\n",
    "    logger.info(f\"{i+1}. {workflow.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphrag.index import run_pipeline_with_config\n",
    "\n",
    "# Run the pipeline\n",
    "async def run_pipeline():\n",
    "    async for result in run_pipeline_with_config(pipeline_config):\n",
    "        if result.errors:\n",
    "            logger.error(f\"Error in workflow {result.workflow}: {result.errors}\")\n",
    "        else:\n",
    "            logger.info(f\"Completed workflow: {result.workflow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:graphrag.index.run:Running pipeline\n",
      "INFO:graphrag.index.storage.file_pipeline_storage:Creating file storage at inputs/hello-graphrag/output\n",
      "INFO:graphrag.index.input.load_input:loading input from root_dir=input\n",
      "INFO:graphrag.index.input.load_input:using file storage for input\n",
      "INFO:graphrag.index.storage.file_pipeline_storage:search inputs/hello-graphrag/input for files matching .*\\.txt$\n",
      "INFO:graphrag.index.input.text:found text files from input, found [('emf-review.txt', {})]\n",
      "INFO:graphrag.index.input.text:Found 1 files, loading 1\n",
      "INFO:graphrag.index.workflows.load:Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']\n",
      "INFO:graphrag.index.run:Final # of rows loaded: 1\n",
      "INFO:graphrag.index.run:Running workflow: create_base_text_units...\n",
      "INFO:graphrag.index.run:dependencies for create_base_text_units: []\n",
      "INFO:datashaper.workflow.workflow:executing verb orderby\n",
      "INFO:datashaper.workflow.workflow:executing verb zip\n",
      "INFO:datashaper.workflow.workflow:executing verb aggregate_override\n",
      "INFO:datashaper.workflow.workflow:executing verb chunk\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:datashaper.workflow.workflow:executing verb unroll\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb genid\n",
      "INFO:datashaper.workflow.workflow:executing verb unzip\n",
      "INFO:datashaper.workflow.workflow:executing verb copy\n",
      "INFO:datashaper.workflow.workflow:executing verb filter\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_base_text_units.parquet\n",
      "INFO:__main__:Completed workflow: create_base_text_units\n",
      "INFO:graphrag.index.run:Running workflow: create_base_extracted_entities...\n",
      "INFO:graphrag.index.run:dependencies for create_base_extracted_entities: ['create_base_text_units']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_text_units.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb entity_extract\n",
      "INFO:datashaper.workflow.workflow:executing verb merge_graphs\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_base_extracted_entities.parquet\n",
      "INFO:__main__:Completed workflow: create_base_extracted_entities\n",
      "INFO:graphrag.index.run:Running workflow: create_final_covariates...\n",
      "INFO:graphrag.index.run:dependencies for create_final_covariates: ['create_base_text_units']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_text_units.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb extract_covariates\n",
      "INFO:datashaper.workflow.workflow:executing verb window\n",
      "INFO:datashaper.workflow.workflow:executing verb genid\n",
      "INFO:datashaper.workflow.workflow:executing verb convert\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/engine/verbs/convert.py:65: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  column_numeric = cast(pd.Series, pd.to_numeric(column, errors=\"ignore\"))\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_final_covariates.parquet\n",
      "INFO:__main__:Completed workflow: create_final_covariates\n",
      "INFO:graphrag.index.run:Running workflow: create_summarized_entities...\n",
      "INFO:graphrag.index.run:dependencies for create_summarized_entities: ['create_base_extracted_entities']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_extracted_entities.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb summarize_descriptions\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_summarized_entities.parquet\n",
      "INFO:__main__:Completed workflow: create_summarized_entities\n",
      "INFO:graphrag.index.run:Running workflow: join_text_units_to_covariate_ids...\n",
      "INFO:graphrag.index.run:dependencies for join_text_units_to_covariate_ids: ['create_final_covariates']\n",
      "INFO:graphrag.index.run:read table from storage: create_final_covariates.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:datashaper.workflow.workflow:executing verb aggregate_override\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table join_text_units_to_covariate_ids.parquet\n",
      "INFO:__main__:Completed workflow: join_text_units_to_covariate_ids\n",
      "INFO:graphrag.index.run:Running workflow: create_base_entity_graph...\n",
      "INFO:graphrag.index.run:dependencies for create_base_entity_graph: ['create_summarized_entities']\n",
      "INFO:graphrag.index.run:read table from storage: create_summarized_entities.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb cluster_graph\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_base_entity_graph.parquet\n",
      "INFO:__main__:Completed workflow: create_base_entity_graph\n",
      "INFO:graphrag.index.run:Running workflow: create_final_entities...\n",
      "INFO:graphrag.index.run:dependencies for create_final_entities: ['create_base_entity_graph']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_entity_graph.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb unpack_graph\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:datashaper.workflow.workflow:executing verb dedupe\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb filter\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "INFO:datashaper.workflow.workflow:executing verb text_split\n",
      "INFO:datashaper.workflow.workflow:executing verb drop\n",
      "INFO:datashaper.workflow.workflow:executing verb merge\n",
      "INFO:datashaper.workflow.workflow:executing verb text_embed\n",
      "INFO:graphrag.index.verbs.text.embed.strategies.openai:embedding 24 inputs via 24 snippets using 2 batches. max_batch_size=16, max_tokens=8191\n",
      "INFO:httpx:HTTP Request: POST http://0.0.0.0:8000/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:graphrag.llm.base.rate_limiting_llm:perf - llm.embedding \"Process\" with 0 retries took 1.1384533126838505. input_tokens=168, output_tokens=0\n",
      "INFO:httpx:HTTP Request: POST http://0.0.0.0:8000/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:graphrag.llm.base.rate_limiting_llm:perf - llm.embedding \"Process\" with 0 retries took 1.1497872238978744. input_tokens=343, output_tokens=0\n",
      "INFO:datashaper.workflow.workflow:executing verb drop\n",
      "INFO:datashaper.workflow.workflow:executing verb filter\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_final_entities.parquet\n",
      "INFO:__main__:Completed workflow: create_final_entities\n",
      "INFO:graphrag.index.run:Running workflow: create_final_nodes...\n",
      "INFO:graphrag.index.run:dependencies for create_final_nodes: ['create_base_entity_graph']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_entity_graph.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb layout_graph\n",
      "INFO:datashaper.workflow.workflow:executing verb unpack_graph\n",
      "INFO:datashaper.workflow.workflow:executing verb unpack_graph\n",
      "INFO:datashaper.workflow.workflow:executing verb filter\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "INFO:datashaper.workflow.workflow:executing verb drop\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb convert\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/engine/verbs/convert.py:72: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  datetime_column = pd.to_datetime(column, errors=\"ignore\")\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/engine/verbs/convert.py:72: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  datetime_column = pd.to_datetime(column, errors=\"ignore\")\n",
      "INFO:datashaper.workflow.workflow:executing verb join\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_final_nodes.parquet\n",
      "INFO:__main__:Completed workflow: create_final_nodes\n",
      "INFO:graphrag.index.run:Running workflow: create_final_communities...\n",
      "INFO:graphrag.index.run:dependencies for create_final_communities: ['create_base_entity_graph']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_entity_graph.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb unpack_graph\n",
      "INFO:datashaper.workflow.workflow:executing verb unpack_graph\n",
      "INFO:datashaper.workflow.workflow:executing verb aggregate_override\n",
      "INFO:datashaper.workflow.workflow:executing verb join\n",
      "INFO:datashaper.workflow.workflow:executing verb join\n",
      "INFO:datashaper.workflow.workflow:executing verb concat\n",
      "INFO:datashaper.workflow.workflow:executing verb filter\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "INFO:datashaper.workflow.workflow:executing verb aggregate_override\n",
      "INFO:datashaper.workflow.workflow:executing verb join\n",
      "INFO:datashaper.workflow.workflow:executing verb filter\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "INFO:datashaper.workflow.workflow:executing verb fill\n",
      "INFO:datashaper.workflow.workflow:executing verb merge\n",
      "INFO:datashaper.workflow.workflow:executing verb copy\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_final_communities.parquet\n",
      "INFO:__main__:Completed workflow: create_final_communities\n",
      "INFO:graphrag.index.run:Running workflow: join_text_units_to_entity_ids...\n",
      "INFO:graphrag.index.run:dependencies for join_text_units_to_entity_ids: ['create_final_entities']\n",
      "INFO:graphrag.index.run:read table from storage: create_final_entities.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:datashaper.workflow.workflow:executing verb unroll\n",
      "INFO:datashaper.workflow.workflow:executing verb aggregate_override\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table join_text_units_to_entity_ids.parquet\n",
      "INFO:__main__:Completed workflow: join_text_units_to_entity_ids\n",
      "INFO:graphrag.index.run:Running workflow: create_final_relationships...\n",
      "INFO:graphrag.index.run:dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']\n",
      "INFO:graphrag.index.run:read table from storage: create_final_nodes.parquet\n",
      "INFO:graphrag.index.run:read table from storage: create_base_entity_graph.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb unpack_graph\n",
      "INFO:datashaper.workflow.workflow:executing verb filter\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb filter\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "INFO:datashaper.workflow.workflow:executing verb drop\n",
      "INFO:datashaper.workflow.workflow:executing verb compute_edge_combined_degree\n",
      "INFO:datashaper.workflow.workflow:executing verb convert\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/engine/verbs/convert.py:65: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  column_numeric = cast(pd.Series, pd.to_numeric(column, errors=\"ignore\"))\n",
      "INFO:datashaper.workflow.workflow:executing verb convert\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_final_relationships.parquet\n",
      "INFO:__main__:Completed workflow: create_final_relationships\n",
      "INFO:graphrag.index.run:Running workflow: join_text_units_to_relationship_ids...\n",
      "INFO:graphrag.index.run:dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']\n",
      "INFO:graphrag.index.run:read table from storage: create_final_relationships.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:datashaper.workflow.workflow:executing verb unroll\n",
      "INFO:datashaper.workflow.workflow:executing verb aggregate_override\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table join_text_units_to_relationship_ids.parquet\n",
      "INFO:__main__:Completed workflow: join_text_units_to_relationship_ids\n",
      "INFO:graphrag.index.run:Running workflow: create_final_community_reports...\n",
      "INFO:graphrag.index.run:dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships', 'create_final_covariates']\n",
      "INFO:graphrag.index.run:read table from storage: create_final_nodes.parquet\n",
      "INFO:graphrag.index.run:read table from storage: create_final_relationships.parquet\n",
      "INFO:graphrag.index.run:read table from storage: create_final_covariates.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb prepare_community_reports_nodes\n",
      "INFO:datashaper.workflow.workflow:executing verb prepare_community_reports_edges\n",
      "INFO:datashaper.workflow.workflow:executing verb prepare_community_reports_claims\n",
      "INFO:datashaper.workflow.workflow:executing verb restore_community_hierarchy\n",
      "INFO:datashaper.workflow.workflow:executing verb prepare_community_reports\n",
      "INFO:graphrag.index.verbs.graph.report.prepare_community_reports:Number of nodes at level=0 => 24\n",
      "INFO:datashaper.workflow.workflow:executing verb create_community_reports\n",
      "INFO:httpx:HTTP Request: POST http://0.0.0.0:8000/openai/deployments/kiku-deployment/chat/completions?api-version=1978-02-16 \"HTTP/1.1 200 OK\"\n",
      "INFO:graphrag.llm.base.rate_limiting_llm:perf - llm.chat \"create_community_report\" with 0 retries took 19.432049790862948. input_tokens=2174, output_tokens=791\n",
      "INFO:datashaper.workflow.workflow:executing verb window\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_final_community_reports.parquet\n",
      "INFO:__main__:Completed workflow: create_final_community_reports\n",
      "INFO:graphrag.index.run:Running workflow: create_final_text_units...\n",
      "INFO:graphrag.index.run:dependencies for create_final_text_units: ['create_base_text_units', 'join_text_units_to_covariate_ids', 'join_text_units_to_relationship_ids', 'join_text_units_to_entity_ids']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_text_units.parquet\n",
      "INFO:graphrag.index.run:read table from storage: join_text_units_to_covariate_ids.parquet\n",
      "INFO:graphrag.index.run:read table from storage: join_text_units_to_relationship_ids.parquet\n",
      "INFO:graphrag.index.run:read table from storage: join_text_units_to_entity_ids.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb join\n",
      "INFO:datashaper.workflow.workflow:executing verb join\n",
      "INFO:datashaper.workflow.workflow:executing verb join\n",
      "INFO:datashaper.workflow.workflow:executing verb aggregate_override\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_final_text_units.parquet\n",
      "INFO:__main__:Completed workflow: create_final_text_units\n",
      "INFO:graphrag.index.run:Running workflow: create_base_documents...\n",
      "INFO:graphrag.index.run:dependencies for create_base_documents: ['create_final_text_units']\n",
      "INFO:graphrag.index.run:read table from storage: create_final_text_units.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb unroll\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb join\n",
      "INFO:datashaper.workflow.workflow:executing verb aggregate_override\n",
      "INFO:datashaper.workflow.workflow:executing verb join\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb convert\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/engine/verbs/convert.py:72: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  datetime_column = pd.to_datetime(column, errors=\"ignore\")\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_base_documents.parquet\n",
      "INFO:__main__:Completed workflow: create_base_documents\n",
      "INFO:graphrag.index.run:Running workflow: create_final_documents...\n",
      "INFO:graphrag.index.run:dependencies for create_final_documents: ['create_base_documents']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_documents.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_final_documents.parquet\n",
      "INFO:__main__:Completed workflow: create_final_documents\n",
      "INFO:__main__:Output files:\n",
      "INFO:__main__:- create_base_extracted_entities.parquet\n",
      "INFO:__main__:- create_final_text_units.parquet\n",
      "INFO:__main__:- join_text_units_to_entity_ids.parquet\n",
      "INFO:__main__:- join_text_units_to_relationship_ids.parquet\n",
      "INFO:__main__:- create_base_documents.parquet\n",
      "INFO:__main__:- join_text_units_to_covariate_ids.parquet\n",
      "INFO:__main__:- create_summarized_entities.parquet\n",
      "INFO:__main__:- create_final_nodes.parquet\n",
      "INFO:__main__:- create_final_entities.parquet\n",
      "INFO:__main__:- create_final_relationships.parquet\n",
      "INFO:__main__:- create_base_entity_graph.parquet\n",
      "INFO:__main__:- create_final_documents.parquet\n",
      "INFO:__main__:- create_final_communities.parquet\n",
      "INFO:__main__:- create_final_covariates.parquet\n",
      "INFO:__main__:- stats.json\n",
      "INFO:__main__:- create_final_community_reports.parquet\n",
      "INFO:__main__:- create_base_text_units.parquet\n",
      "INFO:__main__:- 20240720-201022/reports/logs.json\n",
      "INFO:__main__:- 20240720-192546/reports/logs.json\n",
      "INFO:__main__:- 20240720-191823/reports/logs.json\n",
      "INFO:__main__:- 20240720-193504/reports/logs.json\n",
      "INFO:__main__:Pipeline execution completed.\n"
     ]
    }
   ],
   "source": [
    "# For Jupyter notebooks, use await instead of asyncio.run()\n",
    "await run_pipeline()\n",
    "\n",
    "# Check the output\n",
    "logger.info(\"Output files:\")\n",
    "for file in output_dir.glob(\"**/*\"):\n",
    "    if file.is_file():\n",
    "        logger.info(f\"- {file.relative_to(output_dir)}\")\n",
    "\n",
    "logger.info(\"Pipeline execution completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag-YkYxlOUs-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
