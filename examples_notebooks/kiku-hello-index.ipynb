{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path within the notebook\n",
    "# This will add the parent directory to the Python path, allowing you to import the graphrag package.\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Set up directories\n",
    "root_dir = Path(\"./inputs/hello-graphrag\")\n",
    "input_dir = root_dir / \"input\"\n",
    "output_dir = root_dir / \"output\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "input_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create a sample .txt file if it doesn't exist\n",
    "sample_file = input_dir / \"emf-review.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:graphrag.config.read_dotenv:Loading pipeline .env file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphRagConfig(\n",
       "    llm=LLMParameters(\n",
       "        api_key='bedrock',\n",
       "        type=\"openai_chat\",\n",
       "        model='gpt-4-turbo-preview',\n",
       "        max_tokens=4000,\n",
       "        temperature=0.0,\n",
       "        top_p=1.0,\n",
       "        n=1,\n",
       "        request_timeout=180.0,\n",
       "        api_base=None,\n",
       "        api_version=None,\n",
       "        organization=None,\n",
       "        proxy=None,\n",
       "        cognitive_services_endpoint=None,\n",
       "        deployment_name=None,\n",
       "        model_supports_json=None,\n",
       "        tokens_per_minute=0,\n",
       "        requests_per_minute=0,\n",
       "        max_retries=10,\n",
       "        max_retry_wait=10.0,\n",
       "        sleep_on_rate_limit_recommendation=True,\n",
       "        concurrent_requests=25,\n",
       "    ),\n",
       "    parallelization=ParallelizationParameters(\n",
       "        stagger=0.3,\n",
       "        num_threads=50,\n",
       "    ),\n",
       "    async_mode=<AsyncType.Threaded: 'threaded'>,\n",
       "    root_dir='inputs/hello-graphrag',\n",
       "    reporting=ReportingConfig(\n",
       "        type=\"file\",\n",
       "        base_dir='output/${timestamp}/reports',\n",
       "        connection_string=None,\n",
       "        container_name=None,\n",
       "        storage_account_blob_url=None,\n",
       "    ),\n",
       "    storage=StorageConfig(\n",
       "        type=\"file\",\n",
       "        base_dir='output',\n",
       "        connection_string=None,\n",
       "        container_name=None,\n",
       "        storage_account_blob_url=None,\n",
       "    ),\n",
       "    cache=CacheConfig(\n",
       "        type=\"file\",\n",
       "        base_dir='cache',\n",
       "        connection_string=None,\n",
       "        container_name=None,\n",
       "        storage_account_blob_url=None,\n",
       "    ),\n",
       "    input=InputConfig(\n",
       "        type=\"file\",\n",
       "        file_type=\"text\",\n",
       "        base_dir='input',\n",
       "        connection_string=None,\n",
       "        storage_account_blob_url=None,\n",
       "        container_name=None,\n",
       "        encoding='utf-8',\n",
       "        file_pattern='.*\\\\.txt$',\n",
       "        file_filter=None,\n",
       "        source_column=None,\n",
       "        timestamp_column=None,\n",
       "        timestamp_format=None,\n",
       "        text_column='text',\n",
       "        title_column=None,\n",
       "        document_attribute_columns=[],\n",
       "    ),\n",
       "    embed_graph=EmbedGraphConfig(\n",
       "        enabled=False,\n",
       "        num_walks=10,\n",
       "        walk_length=40,\n",
       "        window_size=2,\n",
       "        iterations=3,\n",
       "        random_seed=597832,\n",
       "        strategy=None,\n",
       "    ),\n",
       "    embeddings=TextEmbeddingConfig(\n",
       "        llm=LLMParameters(\n",
       "            api_key='bedrock',\n",
       "            type=\"openai_embedding\",\n",
       "            model='text-embedding-3-small',\n",
       "            max_tokens=4000,\n",
       "            temperature=0,\n",
       "            top_p=1,\n",
       "            n=1,\n",
       "            request_timeout=180.0,\n",
       "            api_base=None,\n",
       "            api_version=None,\n",
       "            organization=None,\n",
       "            proxy=None,\n",
       "            cognitive_services_endpoint=None,\n",
       "            deployment_name=None,\n",
       "            model_supports_json=None,\n",
       "            tokens_per_minute=0,\n",
       "            requests_per_minute=0,\n",
       "            max_retries=10,\n",
       "            max_retry_wait=10.0,\n",
       "            sleep_on_rate_limit_recommendation=True,\n",
       "            concurrent_requests=25,\n",
       "        ),\n",
       "        parallelization=ParallelizationParameters(\n",
       "            stagger=0.3,\n",
       "            num_threads=50,\n",
       "        ),\n",
       "        async_mode=<AsyncType.Threaded: 'threaded'>,\n",
       "        batch_size=16,\n",
       "        batch_max_tokens=8191,\n",
       "        target=\"required\",\n",
       "        skip=[],\n",
       "        vector_store=None,\n",
       "        strategy=None,\n",
       "    ),\n",
       "    chunks=ChunkingConfig(\n",
       "        size=1200,\n",
       "        overlap=100,\n",
       "        group_by_columns=['id'],\n",
       "        strategy=None,\n",
       "    ),\n",
       "    snapshots=SnapshotsConfig(\n",
       "        graphml=False,\n",
       "        raw_entities=False,\n",
       "        top_level_nodes=False,\n",
       "    ),\n",
       "    entity_extraction=EntityExtractionConfig(\n",
       "        llm=LLMParameters(\n",
       "            api_key='bedrock',\n",
       "            type=\"openai_chat\",\n",
       "            model='gpt-4-turbo-preview',\n",
       "            max_tokens=4000,\n",
       "            temperature=0.0,\n",
       "            top_p=1.0,\n",
       "            n=1,\n",
       "            request_timeout=180.0,\n",
       "            api_base=None,\n",
       "            api_version=None,\n",
       "            organization=None,\n",
       "            proxy=None,\n",
       "            cognitive_services_endpoint=None,\n",
       "            deployment_name=None,\n",
       "            model_supports_json=None,\n",
       "            tokens_per_minute=0,\n",
       "            requests_per_minute=0,\n",
       "            max_retries=10,\n",
       "            max_retry_wait=10.0,\n",
       "            sleep_on_rate_limit_recommendation=True,\n",
       "            concurrent_requests=25,\n",
       "        ),\n",
       "        parallelization=ParallelizationParameters(\n",
       "            stagger=0.3,\n",
       "            num_threads=50,\n",
       "        ),\n",
       "        async_mode=<AsyncType.Threaded: 'threaded'>,\n",
       "        prompt=None,\n",
       "        entity_types=[\n",
       "            'organization',\n",
       "            'person',\n",
       "            'geo',\n",
       "            'event',\n",
       "        ],\n",
       "        max_gleanings=1,\n",
       "        strategy=None,\n",
       "    ),\n",
       "    summarize_descriptions=SummarizeDescriptionsConfig(\n",
       "        llm=LLMParameters(\n",
       "            api_key='bedrock',\n",
       "            type=\"openai_chat\",\n",
       "            model='gpt-4-turbo-preview',\n",
       "            max_tokens=4000,\n",
       "            temperature=0.0,\n",
       "            top_p=1.0,\n",
       "            n=1,\n",
       "            request_timeout=180.0,\n",
       "            api_base=None,\n",
       "            api_version=None,\n",
       "            organization=None,\n",
       "            proxy=None,\n",
       "            cognitive_services_endpoint=None,\n",
       "            deployment_name=None,\n",
       "            model_supports_json=None,\n",
       "            tokens_per_minute=0,\n",
       "            requests_per_minute=0,\n",
       "            max_retries=10,\n",
       "            max_retry_wait=10.0,\n",
       "            sleep_on_rate_limit_recommendation=True,\n",
       "            concurrent_requests=25,\n",
       "        ),\n",
       "        parallelization=ParallelizationParameters(\n",
       "            stagger=0.3,\n",
       "            num_threads=50,\n",
       "        ),\n",
       "        async_mode=<AsyncType.Threaded: 'threaded'>,\n",
       "        prompt=None,\n",
       "        max_length=500,\n",
       "        strategy=None,\n",
       "    ),\n",
       "    community_reports=CommunityReportsConfig(\n",
       "        llm=LLMParameters(\n",
       "            api_key='bedrock',\n",
       "            type=\"openai_chat\",\n",
       "            model='gpt-4-turbo-preview',\n",
       "            max_tokens=4000,\n",
       "            temperature=0.0,\n",
       "            top_p=1.0,\n",
       "            n=1,\n",
       "            request_timeout=180.0,\n",
       "            api_base=None,\n",
       "            api_version=None,\n",
       "            organization=None,\n",
       "            proxy=None,\n",
       "            cognitive_services_endpoint=None,\n",
       "            deployment_name=None,\n",
       "            model_supports_json=None,\n",
       "            tokens_per_minute=0,\n",
       "            requests_per_minute=0,\n",
       "            max_retries=10,\n",
       "            max_retry_wait=10.0,\n",
       "            sleep_on_rate_limit_recommendation=True,\n",
       "            concurrent_requests=25,\n",
       "        ),\n",
       "        parallelization=ParallelizationParameters(\n",
       "            stagger=0.3,\n",
       "            num_threads=50,\n",
       "        ),\n",
       "        async_mode=<AsyncType.Threaded: 'threaded'>,\n",
       "        prompt=None,\n",
       "        max_length=2000,\n",
       "        max_input_length=8000,\n",
       "        strategy=None,\n",
       "    ),\n",
       "    claim_extraction=ClaimExtractionConfig(\n",
       "        llm=LLMParameters(\n",
       "            api_key='bedrock',\n",
       "            type=\"openai_chat\",\n",
       "            model='gpt-4-turbo-preview',\n",
       "            max_tokens=4000,\n",
       "            temperature=0.0,\n",
       "            top_p=1.0,\n",
       "            n=1,\n",
       "            request_timeout=180.0,\n",
       "            api_base=None,\n",
       "            api_version=None,\n",
       "            organization=None,\n",
       "            proxy=None,\n",
       "            cognitive_services_endpoint=None,\n",
       "            deployment_name=None,\n",
       "            model_supports_json=None,\n",
       "            tokens_per_minute=0,\n",
       "            requests_per_minute=0,\n",
       "            max_retries=10,\n",
       "            max_retry_wait=10.0,\n",
       "            sleep_on_rate_limit_recommendation=True,\n",
       "            concurrent_requests=25,\n",
       "        ),\n",
       "        parallelization=ParallelizationParameters(\n",
       "            stagger=0.3,\n",
       "            num_threads=50,\n",
       "        ),\n",
       "        async_mode=<AsyncType.Threaded: 'threaded'>,\n",
       "        enabled=True,\n",
       "        prompt=None,\n",
       "        description='Any claims or facts that could be relevant to information discovery.',\n",
       "        max_gleanings=1,\n",
       "        strategy=None,\n",
       "    ),\n",
       "    cluster_graph=ClusterGraphConfig(\n",
       "        max_cluster_size=10,\n",
       "        strategy=None,\n",
       "    ),\n",
       "    umap=UmapConfig(\n",
       "        enabled=False,\n",
       "    ),\n",
       "    local_search=LocalSearchConfig(\n",
       "        text_unit_prop=0.5,\n",
       "        community_prop=0.1,\n",
       "        conversation_history_max_turns=5,\n",
       "        top_k_entities=10,\n",
       "        top_k_relationships=10,\n",
       "        temperature=0.0,\n",
       "        top_p=1.0,\n",
       "        n=1,\n",
       "        max_tokens=12000,\n",
       "        llm_max_tokens=2000,\n",
       "    ),\n",
       "    global_search=GlobalSearchConfig(\n",
       "        temperature=0.0,\n",
       "        top_p=1.0,\n",
       "        n=1,\n",
       "        max_tokens=12000,\n",
       "        data_max_tokens=12000,\n",
       "        map_max_tokens=1000,\n",
       "        reduce_max_tokens=2000,\n",
       "        concurrency=32,\n",
       "    ),\n",
       "    encoding_model='cl100k_base',\n",
       "    skip_workflows=[],\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphrag.config import create_graphrag_config\n",
    "from graphrag.config.enums import InputFileType, InputType\n",
    "\n",
    "# Create a basic configuration\n",
    "config = create_graphrag_config(\n",
    "    root_dir=str(root_dir),\n",
    "    values={\n",
    "        \"input\": {\n",
    "            \"type\": InputType.file,\n",
    "            \"file_type\": InputFileType.text,\n",
    "            \"base_dir\": \"input\",\n",
    "            \"file_pattern\": r\".*\\.txt$\",\n",
    "        },\n",
    "        \"storage\": {\"base_dir\": \"output\"},\n",
    "        \"claim_extraction\": {\n",
    "            \"enabled\": True,            \n",
    "        },\n",
    "        # Simplify the pipeline for this test\n",
    "        # skip_workflows=[\n",
    "        #     \"create_final_community_reports\",\n",
    "        #     \"create_final_covariates\",\n",
    "        # ],\n",
    "    },\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:graphrag.index.create_pipeline_config:Using LLM Config {\n",
      "    \"api_key\": \"*****\",\n",
      "    \"type\": \"openai_chat\",\n",
      "    \"model\": \"gpt-4-turbo-preview\",\n",
      "    \"max_tokens\": 4000,\n",
      "    \"temperature\": 0.0,\n",
      "    \"top_p\": 1.0,\n",
      "    \"n\": 1,\n",
      "    \"request_timeout\": 180.0,\n",
      "    \"api_base\": null,\n",
      "    \"api_version\": null,\n",
      "    \"organization\": null,\n",
      "    \"proxy\": null,\n",
      "    \"cognitive_services_endpoint\": null,\n",
      "    \"deployment_name\": null,\n",
      "    \"model_supports_json\": null,\n",
      "    \"tokens_per_minute\": 0,\n",
      "    \"requests_per_minute\": 0,\n",
      "    \"max_retries\": 10,\n",
      "    \"max_retry_wait\": 10.0,\n",
      "    \"sleep_on_rate_limit_recommendation\": true,\n",
      "    \"concurrent_requests\": 25\n",
      "}\n",
      "INFO:graphrag.index.create_pipeline_config:Using Embeddings Config {\n",
      "    \"api_key\": \"*****\",\n",
      "    \"type\": \"openai_embedding\",\n",
      "    \"model\": \"text-embedding-3-small\",\n",
      "    \"max_tokens\": 4000,\n",
      "    \"temperature\": 0,\n",
      "    \"top_p\": 1,\n",
      "    \"n\": 1,\n",
      "    \"request_timeout\": 180.0,\n",
      "    \"api_base\": null,\n",
      "    \"api_version\": null,\n",
      "    \"organization\": null,\n",
      "    \"proxy\": null,\n",
      "    \"cognitive_services_endpoint\": null,\n",
      "    \"deployment_name\": null,\n",
      "    \"model_supports_json\": null,\n",
      "    \"tokens_per_minute\": 0,\n",
      "    \"requests_per_minute\": 0,\n",
      "    \"max_retries\": 10,\n",
      "    \"max_retry_wait\": 10.0,\n",
      "    \"sleep_on_rate_limit_recommendation\": true,\n",
      "    \"concurrent_requests\": 25\n",
      "}\n",
      "INFO:graphrag.index.create_pipeline_config:skipping workflows \n",
      "INFO:__main__:\n",
      "\n",
      "Initial Workflow order:\n",
      "INFO:__main__:1. create_base_documents\n",
      "INFO:__main__:2. create_final_documents\n",
      "INFO:__main__:3. create_base_text_units\n",
      "INFO:__main__:4. join_text_units_to_entity_ids\n",
      "INFO:__main__:5. join_text_units_to_relationship_ids\n",
      "INFO:__main__:6. join_text_units_to_covariate_ids\n",
      "INFO:__main__:7. create_final_text_units\n",
      "INFO:__main__:8. create_base_extracted_entities\n",
      "INFO:__main__:9. create_summarized_entities\n",
      "INFO:__main__:10. create_base_entity_graph\n",
      "INFO:__main__:11. create_final_entities\n",
      "INFO:__main__:12. create_final_relationships\n",
      "INFO:__main__:13. create_final_nodes\n",
      "INFO:__main__:14. create_final_communities\n",
      "INFO:__main__:15. create_final_community_reports\n",
      "INFO:__main__:16. create_final_covariates\n"
     ]
    }
   ],
   "source": [
    "from graphrag.index import create_pipeline_config\n",
    "\n",
    "# Create the pipeline configuration\n",
    "pipeline_config = create_pipeline_config(config, verbose=True)\n",
    "\n",
    "# Log the initial workflow order\n",
    "logger.info(\"\\n\\nInitial Workflow order:\")\n",
    "for i, workflow in enumerate(pipeline_config.workflows):\n",
    "    logger.info(f\"{i+1}. {workflow.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphrag.index import run_pipeline_with_config\n",
    "\n",
    "# Run the pipeline\n",
    "async def run_pipeline():\n",
    "    async for result in run_pipeline_with_config(pipeline_config):\n",
    "        if result.errors:\n",
    "            logger.error(f\"Error in workflow {result.workflow}: {result.errors}\")\n",
    "        else:\n",
    "            logger.info(f\"Completed workflow: {result.workflow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:graphrag.index.run:Running pipeline\n",
      "INFO:graphrag.index.storage.file_pipeline_storage:Creating file storage at inputs/hello-graphrag/output\n",
      "INFO:graphrag.index.input.load_input:loading input from root_dir=input\n",
      "INFO:graphrag.index.input.load_input:using file storage for input\n",
      "INFO:graphrag.index.storage.file_pipeline_storage:search inputs/hello-graphrag/input for files matching .*\\.txt$\n",
      "INFO:graphrag.index.input.text:found text files from input, found [('emf-review.txt', {})]\n",
      "INFO:graphrag.index.input.text:Found 1 files, loading 1\n",
      "INFO:graphrag.index.workflows.load:Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']\n",
      "INFO:graphrag.index.run:Final # of rows loaded: 1\n",
      "INFO:graphrag.index.run:Running workflow: create_base_text_units...\n",
      "INFO:graphrag.index.run:dependencies for create_base_text_units: []\n",
      "INFO:datashaper.workflow.workflow:executing verb orderby\n",
      "INFO:datashaper.workflow.workflow:executing verb zip\n",
      "INFO:datashaper.workflow.workflow:executing verb aggregate_override\n",
      "INFO:datashaper.workflow.workflow:executing verb chunk\n",
      "INFO:datashaper.workflow.workflow:executing verb select\n",
      "INFO:datashaper.workflow.workflow:executing verb unroll\n",
      "INFO:datashaper.workflow.workflow:executing verb rename\n",
      "INFO:datashaper.workflow.workflow:executing verb genid\n",
      "INFO:datashaper.workflow.workflow:executing verb unzip\n",
      "INFO:datashaper.workflow.workflow:executing verb copy\n",
      "INFO:datashaper.workflow.workflow:executing verb filter\n",
      "/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_base_text_units.parquet\n",
      "INFO:__main__:Completed workflow: create_base_text_units\n",
      "INFO:graphrag.index.run:Running workflow: create_base_extracted_entities...\n",
      "INFO:graphrag.index.run:dependencies for create_base_extracted_entities: ['create_base_text_units']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_text_units.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb entity_extract\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Error Invoking LLM details={'input': '\\n-Goal-\\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\\n\\n-Steps-\\n1. Identify all entities. For each identified entity, extract the following information:\\n- entity_name: Name of the entity, capitalized\\n- entity_type: One of the following types: [organization,person,geo,event]\\n- entity_description: Comprehensive description of the entity\\'s attributes and activities\\nFormat each entity as (\"entity\"<|><entity_name><|><entity_type><|><entity_description>\\n\\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\\nFor each pair of related entities, extract the following information:\\n- source_entity: name of the source entity, as identified in step 1\\n- target_entity: name of the target entity, as identified in step 1\\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\\n Format each relationship as (\"relationship\"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\\n\\n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\\n\\n4. When finished, output <|COMPLETE|>\\n\\n######################\\n-Examples-\\n######################\\nExample 1:\\n\\nEntity_types: [person, technology, mission, organization, location]\\nText:\\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor\\'s authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan\\'s shared commitment to discovery was an unspoken rebellion against Cruz\\'s narrowing vision of control and order.\\n\\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. “If this tech can be understood...\" Taylor said, their voice quieter, \"It could change the game for us. For all of us.”\\n\\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor\\'s, a wordless clash of wills softening into an uneasy truce.\\n\\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\\n################\\nOutput:\\n(\"entity\"<|>\"Alex\"<|>\"person\"<|>\"Alex is a character who experiences frustration and is observant of the dynamics among other characters.\")##\\n(\"entity\"<|>\"Taylor\"<|>\"person\"<|>\"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.\")##\\n(\"entity\"<|>\"Jordan\"<|>\"person\"<|>\"Jordan shares a commitment to discovery and has a significant interaction with Taylor regarding a device.\")##\\n(\"entity\"<|>\"Cruz\"<|>\"person\"<|>\"Cruz is associated with a vision of control and order, influencing the dynamics among other characters.\")##\\n(\"entity\"<|>\"The Device\"<|>\"technology\"<|>\"The Device is central to the story, with potential game-changing implications, and is revered by Taylor.\")##\\n(\"relationship\"<|>\"Alex\"<|>\"Taylor\"<|>\"Alex is affected by Taylor\\'s authoritarian certainty and observes changes in Taylor\\'s attitude towards the device.\"<|>7)##\\n(\"relationship\"<|>\"Alex\"<|>\"Jordan\"<|>\"Alex and Jordan share a commitment to discovery, which contrasts with Cruz\\'s vision.\"<|>6)##\\n(\"relationship\"<|>\"Taylor\"<|>\"Jordan\"<|>\"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce.\"<|>8)##\\n(\"relationship\"<|>\"Jordan\"<|>\"Cruz\"<|>\"Jordan\\'s commitment to discovery is in rebellion against Cruz\\'s vision of control and order.\"<|>5)##\\n(\"relationship\"<|>\"Taylor\"<|>\"The Device\"<|>\"Taylor shows reverence towards the device, indicating its importance and potential impact.\"<|>9)<|COMPLETE|>\\n#############################\\nExample 2:\\n\\nEntity_types: [person, technology, mission, organization, location]\\nText:\\nThey were no longer mere operatives; they had become guardians of a threshold, keepers of a message from a realm beyond stars and stripes. This elevation in their mission could not be shackled by regulations and established protocols—it demanded a new perspective, a new resolve.\\n\\nTension threaded through the dialogue of beeps and static as communications with Washington buzzed in the background. The team stood, a portentous air enveloping them. It was clear that the decisions they made in the ensuing hours could redefine humanity\\'s place in the cosmos or condemn them to ignorance and potential peril.\\n\\nTheir connection to the stars solidified, the group moved to address the crystallizing warning, shifting from passive recipients to active participants. Mercer\\'s latter instincts gained precedence— the team\\'s mandate had evolved, no longer solely to observe and report but to interact and prepare. A metamorphosis had begun, and Operation: Dulce hummed with the newfound frequency of their daring, a tone set not by the earthly\\n#############\\nOutput:\\n(\"entity\"<|>\"Washington\"<|>\"location\"<|>\"Washington is a location where communications are being received, indicating its importance in the decision-making process.\")##\\n(\"entity\"<|>\"Operation: Dulce\"<|>\"mission\"<|>\"Operation: Dulce is described as a mission that has evolved to interact and prepare, indicating a significant shift in objectives and activities.\")##\\n(\"entity\"<|>\"The team\"<|>\"organization\"<|>\"The team is portrayed as a group of individuals who have transitioned from passive observers to active participants in a mission, showing a dynamic change in their role.\")##\\n(\"relationship\"<|>\"The team\"<|>\"Washington\"<|>\"The team receives communications from Washington, which influences their decision-making process.\"<|>7)##\\n(\"relationship\"<|>\"The team\"<|>\"Operation: Dulce\"<|>\"The team is directly involved in Operation: Dulce, executing its evolved objectives and activities.\"<|>9)<|COMPLETE|>\\n#############################\\nExample 3:\\n\\nEntity_types: [person, role, technology, organization, event, location, concept]\\nText:\\ntheir voice slicing through the buzz of activity. \"Control may be an illusion when facing an intelligence that literally writes its own rules,\" they stated stoically, casting a watchful eye over the flurry of data.\\n\\n\"It\\'s like it\\'s learning to communicate,\" offered Sam Rivera from a nearby interface, their youthful energy boding a mix of awe and anxiety. \"This gives talking to strangers\\' a whole new meaning.\"\\n\\nAlex surveyed his team—each face a study in concentration, determination, and not a small measure of trepidation. \"This might well be our first contact,\" he acknowledged, \"And we need to be ready for whatever answers back.\"\\n\\nTogether, they stood on the edge of the unknown, forging humanity\\'s response to a message from the heavens. The ensuing silence was palpable—a collective introspection about their role in this grand cosmic play, one that could rewrite human history.\\n\\nThe encrypted dialogue continued to unfold, its intricate patterns showing an almost uncanny anticipation\\n#############\\nOutput:\\n(\"entity\"<|>\"Sam Rivera\"<|>\"person\"<|>\"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.\")##\\n(\"entity\"<|>\"Alex\"<|>\"person\"<|>\"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.\")##\\n(\"entity\"<|>\"Control\"<|>\"concept\"<|>\"Control refers to the ability to manage or govern, which is challenged by an intelligence that writes its own rules.\")##\\n(\"entity\"<|>\"Intelligence\"<|>\"concept\"<|>\"Intelligence here refers to an unknown entity capable of writing its own rules and learning to communicate.\")##\\n(\"entity\"<|>\"First Contact\"<|>\"event\"<|>\"First Contact is the potential initial communication between humanity and an unknown intelligence.\")##\\n(\"entity\"<|>\"Humanity\\'s Response\"<|>\"event\"<|>\"Humanity\\'s Response is the collective action taken by Alex\\'s team in response to a message from an unknown intelligence.\")##\\n(\"relationship\"<|>\"Sam Rivera\"<|>\"Intelligence\"<|>\"Sam Rivera is directly involved in the process of learning to communicate with the unknown intelligence.\"<|>9)##\\n(\"relationship\"<|>\"Alex\"<|>\"First Contact\"<|>\"Alex leads the team that might be making the First Contact with the unknown intelligence.\"<|>10)##\\n(\"relationship\"<|>\"Alex\"<|>\"Humanity\\'s Response\"<|>\"Alex and his team are the key figures in Humanity\\'s Response to the unknown intelligence.\"<|>8)##\\n(\"relationship\"<|>\"Control\"<|>\"Intelligence\"<|>\"The concept of Control is challenged by the Intelligence that writes its own rules.\"<|>7)<|COMPLETE|>\\n#############################\\n-Real Data-\\n######################\\nEntity_types: organization,person,geo,event\\nText: Review of Elements of Mathematics: Foundations\\nPosted on June 8, 2023\\n\\nAbout two years ago, Peatie hit a wall in math. He had been using and enjoying Art of Problem Solving materials for years, completing Beast Academy 3-5 and (to my surprise) enjoying the hefty tome that is AoPS PreAlgebra. But partway through the Intro to Algebra book, something just wasn’t clicking: some chapters he could breeze through with ease, while others just didn’t seem to make sense for him.\\n\\nOf course, I did what any sane homeschooling parent would do: I panicked. Peatie has loved math since the time he first discovered that he could count his fingers, and back in kindergarten he was clear enough on his preferences to inform me, “I want HARD math, Mommy!” In fact, math is one of the few areas in his life where he seems to thrive on challenge–but he was no longer thriving with the challenge of Art of Problem Solving, and my math skills were too rusty to be of much help. But the general consensus of everyone on the internet is that if you want your kid to have the best, most challenging math, AoPS is the way to go. I was clearly failing my child!\\n\\nIn the midst of this weeks-long panic, I somehow ran across a mention of the Institute for Mathematics and Computer Science (IMACS) and their challenging middle school curricula, Elements of Mathematics: Foundations. I could find very little information about the course, but what little I found seemed promising. Noting that the first course (of 18, intended to cover a three-year period) was offered for free, I thought I’d let Peatie try it out. He loved it!\\n\\n\\nHere’s a sample screenshot from somewhere in the middle of the second year of material, just so you can get an idea of the format of the program.\\nFor the past two years now, Peatie has been working through EMF courses. Since I still rarely see these mentioned online, I thought maybe someone would benefit from a review of them.\\n\\nEMF consists of 18 courses of varying lengths, intended to take a middle school student through what’s traditionally considered Prealgebra, Algebra 1, Algebra 2, Geometry, and Precalculus over the course of three years.\\n\\nThere are a few downsides to this curricula:\\n\\nWhile there are in-person classes for those local to IMACS, most of the world would be accessing these classes via the internet. You need a reliable internet connection with speed adequate for downloading the videos in order to do this course. If your internet goes down, you’re outta luck.\\nThe symbols and terminology used in this program are so vastly different than those in traditional math classes that parents will likely be able to offer very little help if their student is stuck. Sometimes my son simply needs me to stand in the room as a sounding board, and sometimes I can offer suggestions like, “Why don’t you start over? There’s a chance you made a mistake that you aren’t noticing.” Other than that, I’m not much use. There is a help forum available, and many questions have a little “?” icon with past students’ questions and the suggestions offered to them, but some kids might find this to be too little direct assistance if they’re used to a solution manual or the possibility of parent assistance.\\nBecause this program is so different from others, there’s no way to start midway through the program. Every student must start from the very first course. This caused me some hesitation: Peatie had already completed a very solid Prealgebra course and was most of the way through what would be considered Algebra 1. It felt like I would be consigning him to repeat old material and generally slowing his progress by having him start over. I eventually came to my senses, reminding myself that education isn’t a race and it would be far better for him to repeat material and know it very well than to rush ahead just so he could complete Calculus as a high school freshman (and why?). For all my agonizing, he had no complaints about what he was doing. Despite the fact that the first courses he was taking were part of a “Pre-Algebra Plus Course Pack,” the approach and scope were so vastly different from what he’d been doing (with titles like “Operational Systems,” “Ordered n-Tuples,” and “Number Theory”) that it didn’t feel at all like repetition.\\nThe pacing for this program is a challenge. Though you know how many courses they expect you to complete in a traditional school year, some courses are much longer or more complex than others, so being halfway through the courses might not mean that you’re halfway through the curriculum. For the first year, IMACS offers a week-by-week progress guide to help the students pace themselves. After that, however, there’s no more guidance offered. While I realize that it’s wonderful to work at your own pace, it’s nice to have some idea how long the course creators expect the material to take. Particularly since my son is a slow worker who is easily side-tracked by his ADHD, it’s nice to have a goal to help him stay on track (and give me an idea whether those three pages took him all week because the problems were especially hard or because he got distracted by the graphing process). *Update: While he managed to finish the first year of courses in one year and looked like he was on track with the second year, the last two courses for the year (13 & 14) were waaay longer than the ones he’d taken so far. He ended up taking about an extra seven months to get through them. That said, I finally found a pacing guide that assigns 450 days for courses 10-14 at 4-5 hours per week. I know my kid is a plodder and distractable,\\n######################\\nOutput:'}\n",
      "ERROR:root:error extracting graph\n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n",
      "    result = await self._process_document(text, prompt_variables)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 151, in _process_document\n",
      "    response = await self._llm(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n",
      "    result = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n",
      "    return await self._delegate(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n",
      "    output = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n",
      "    result = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n",
      "    result, start = await execute_with_retry()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n",
      "    async for attempt in retryer:\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/miniconda3/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/miniconda3/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n",
      "    return await do_attempt(), start\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n",
      "    return await self._delegate(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/base_llm.py\", line 49, in __call__\n",
      "    return await self._invoke(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n",
      "    output = await self._execute_llm(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n",
      "    completion = await self.client.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1805, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1503, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1599, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: bedrock. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Entity Extraction Error details={'doc_index': 0, 'text': 'Review of Elements of Mathematics: Foundations\\nPosted on June 8, 2023\\n\\nAbout two years ago, Peatie hit a wall in math. He had been using and enjoying Art of Problem Solving materials for years, completing Beast Academy 3-5 and (to my surprise) enjoying the hefty tome that is AoPS PreAlgebra. But partway through the Intro to Algebra book, something just wasn’t clicking: some chapters he could breeze through with ease, while others just didn’t seem to make sense for him.\\n\\nOf course, I did what any sane homeschooling parent would do: I panicked. Peatie has loved math since the time he first discovered that he could count his fingers, and back in kindergarten he was clear enough on his preferences to inform me, “I want HARD math, Mommy!” In fact, math is one of the few areas in his life where he seems to thrive on challenge–but he was no longer thriving with the challenge of Art of Problem Solving, and my math skills were too rusty to be of much help. But the general consensus of everyone on the internet is that if you want your kid to have the best, most challenging math, AoPS is the way to go. I was clearly failing my child!\\n\\nIn the midst of this weeks-long panic, I somehow ran across a mention of the Institute for Mathematics and Computer Science (IMACS) and their challenging middle school curricula, Elements of Mathematics: Foundations. I could find very little information about the course, but what little I found seemed promising. Noting that the first course (of 18, intended to cover a three-year period) was offered for free, I thought I’d let Peatie try it out. He loved it!\\n\\n\\nHere’s a sample screenshot from somewhere in the middle of the second year of material, just so you can get an idea of the format of the program.\\nFor the past two years now, Peatie has been working through EMF courses. Since I still rarely see these mentioned online, I thought maybe someone would benefit from a review of them.\\n\\nEMF consists of 18 courses of varying lengths, intended to take a middle school student through what’s traditionally considered Prealgebra, Algebra 1, Algebra 2, Geometry, and Precalculus over the course of three years.\\n\\nThere are a few downsides to this curricula:\\n\\nWhile there are in-person classes for those local to IMACS, most of the world would be accessing these classes via the internet. You need a reliable internet connection with speed adequate for downloading the videos in order to do this course. If your internet goes down, you’re outta luck.\\nThe symbols and terminology used in this program are so vastly different than those in traditional math classes that parents will likely be able to offer very little help if their student is stuck. Sometimes my son simply needs me to stand in the room as a sounding board, and sometimes I can offer suggestions like, “Why don’t you start over? There’s a chance you made a mistake that you aren’t noticing.” Other than that, I’m not much use. There is a help forum available, and many questions have a little “?” icon with past students’ questions and the suggestions offered to them, but some kids might find this to be too little direct assistance if they’re used to a solution manual or the possibility of parent assistance.\\nBecause this program is so different from others, there’s no way to start midway through the program. Every student must start from the very first course. This caused me some hesitation: Peatie had already completed a very solid Prealgebra course and was most of the way through what would be considered Algebra 1. It felt like I would be consigning him to repeat old material and generally slowing his progress by having him start over. I eventually came to my senses, reminding myself that education isn’t a race and it would be far better for him to repeat material and know it very well than to rush ahead just so he could complete Calculus as a high school freshman (and why?). For all my agonizing, he had no complaints about what he was doing. Despite the fact that the first courses he was taking were part of a “Pre-Algebra Plus Course Pack,” the approach and scope were so vastly different from what he’d been doing (with titles like “Operational Systems,” “Ordered n-Tuples,” and “Number Theory”) that it didn’t feel at all like repetition.\\nThe pacing for this program is a challenge. Though you know how many courses they expect you to complete in a traditional school year, some courses are much longer or more complex than others, so being halfway through the courses might not mean that you’re halfway through the curriculum. For the first year, IMACS offers a week-by-week progress guide to help the students pace themselves. After that, however, there’s no more guidance offered. While I realize that it’s wonderful to work at your own pace, it’s nice to have some idea how long the course creators expect the material to take. Particularly since my son is a slow worker who is easily side-tracked by his ADHD, it’s nice to have a goal to help him stay on track (and give me an idea whether those three pages took him all week because the problems were especially hard or because he got distracted by the graphing process). *Update: While he managed to finish the first year of courses in one year and looked like he was on track with the second year, the last two courses for the year (13 & 14) were waaay longer than the ones he’d taken so far. He ended up taking about an extra seven months to get through them. That said, I finally found a pacing guide that assigns 450 days for courses 10-14 at 4-5 hours per week. I know my kid is a plodder and distractable,'}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Error Invoking LLM details={'input': '\\n-Goal-\\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\\n\\n-Steps-\\n1. Identify all entities. For each identified entity, extract the following information:\\n- entity_name: Name of the entity, capitalized\\n- entity_type: One of the following types: [organization,person,geo,event]\\n- entity_description: Comprehensive description of the entity\\'s attributes and activities\\nFormat each entity as (\"entity\"<|><entity_name><|><entity_type><|><entity_description>\\n\\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\\nFor each pair of related entities, extract the following information:\\n- source_entity: name of the source entity, as identified in step 1\\n- target_entity: name of the target entity, as identified in step 1\\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\\n Format each relationship as (\"relationship\"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\\n\\n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\\n\\n4. When finished, output <|COMPLETE|>\\n\\n######################\\n-Examples-\\n######################\\nExample 1:\\n\\nEntity_types: [person, technology, mission, organization, location]\\nText:\\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor\\'s authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan\\'s shared commitment to discovery was an unspoken rebellion against Cruz\\'s narrowing vision of control and order.\\n\\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. “If this tech can be understood...\" Taylor said, their voice quieter, \"It could change the game for us. For all of us.”\\n\\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor\\'s, a wordless clash of wills softening into an uneasy truce.\\n\\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\\n################\\nOutput:\\n(\"entity\"<|>\"Alex\"<|>\"person\"<|>\"Alex is a character who experiences frustration and is observant of the dynamics among other characters.\")##\\n(\"entity\"<|>\"Taylor\"<|>\"person\"<|>\"Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.\")##\\n(\"entity\"<|>\"Jordan\"<|>\"person\"<|>\"Jordan shares a commitment to discovery and has a significant interaction with Taylor regarding a device.\")##\\n(\"entity\"<|>\"Cruz\"<|>\"person\"<|>\"Cruz is associated with a vision of control and order, influencing the dynamics among other characters.\")##\\n(\"entity\"<|>\"The Device\"<|>\"technology\"<|>\"The Device is central to the story, with potential game-changing implications, and is revered by Taylor.\")##\\n(\"relationship\"<|>\"Alex\"<|>\"Taylor\"<|>\"Alex is affected by Taylor\\'s authoritarian certainty and observes changes in Taylor\\'s attitude towards the device.\"<|>7)##\\n(\"relationship\"<|>\"Alex\"<|>\"Jordan\"<|>\"Alex and Jordan share a commitment to discovery, which contrasts with Cruz\\'s vision.\"<|>6)##\\n(\"relationship\"<|>\"Taylor\"<|>\"Jordan\"<|>\"Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce.\"<|>8)##\\n(\"relationship\"<|>\"Jordan\"<|>\"Cruz\"<|>\"Jordan\\'s commitment to discovery is in rebellion against Cruz\\'s vision of control and order.\"<|>5)##\\n(\"relationship\"<|>\"Taylor\"<|>\"The Device\"<|>\"Taylor shows reverence towards the device, indicating its importance and potential impact.\"<|>9)<|COMPLETE|>\\n#############################\\nExample 2:\\n\\nEntity_types: [person, technology, mission, organization, location]\\nText:\\nThey were no longer mere operatives; they had become guardians of a threshold, keepers of a message from a realm beyond stars and stripes. This elevation in their mission could not be shackled by regulations and established protocols—it demanded a new perspective, a new resolve.\\n\\nTension threaded through the dialogue of beeps and static as communications with Washington buzzed in the background. The team stood, a portentous air enveloping them. It was clear that the decisions they made in the ensuing hours could redefine humanity\\'s place in the cosmos or condemn them to ignorance and potential peril.\\n\\nTheir connection to the stars solidified, the group moved to address the crystallizing warning, shifting from passive recipients to active participants. Mercer\\'s latter instincts gained precedence— the team\\'s mandate had evolved, no longer solely to observe and report but to interact and prepare. A metamorphosis had begun, and Operation: Dulce hummed with the newfound frequency of their daring, a tone set not by the earthly\\n#############\\nOutput:\\n(\"entity\"<|>\"Washington\"<|>\"location\"<|>\"Washington is a location where communications are being received, indicating its importance in the decision-making process.\")##\\n(\"entity\"<|>\"Operation: Dulce\"<|>\"mission\"<|>\"Operation: Dulce is described as a mission that has evolved to interact and prepare, indicating a significant shift in objectives and activities.\")##\\n(\"entity\"<|>\"The team\"<|>\"organization\"<|>\"The team is portrayed as a group of individuals who have transitioned from passive observers to active participants in a mission, showing a dynamic change in their role.\")##\\n(\"relationship\"<|>\"The team\"<|>\"Washington\"<|>\"The team receives communications from Washington, which influences their decision-making process.\"<|>7)##\\n(\"relationship\"<|>\"The team\"<|>\"Operation: Dulce\"<|>\"The team is directly involved in Operation: Dulce, executing its evolved objectives and activities.\"<|>9)<|COMPLETE|>\\n#############################\\nExample 3:\\n\\nEntity_types: [person, role, technology, organization, event, location, concept]\\nText:\\ntheir voice slicing through the buzz of activity. \"Control may be an illusion when facing an intelligence that literally writes its own rules,\" they stated stoically, casting a watchful eye over the flurry of data.\\n\\n\"It\\'s like it\\'s learning to communicate,\" offered Sam Rivera from a nearby interface, their youthful energy boding a mix of awe and anxiety. \"This gives talking to strangers\\' a whole new meaning.\"\\n\\nAlex surveyed his team—each face a study in concentration, determination, and not a small measure of trepidation. \"This might well be our first contact,\" he acknowledged, \"And we need to be ready for whatever answers back.\"\\n\\nTogether, they stood on the edge of the unknown, forging humanity\\'s response to a message from the heavens. The ensuing silence was palpable—a collective introspection about their role in this grand cosmic play, one that could rewrite human history.\\n\\nThe encrypted dialogue continued to unfold, its intricate patterns showing an almost uncanny anticipation\\n#############\\nOutput:\\n(\"entity\"<|>\"Sam Rivera\"<|>\"person\"<|>\"Sam Rivera is a member of a team working on communicating with an unknown intelligence, showing a mix of awe and anxiety.\")##\\n(\"entity\"<|>\"Alex\"<|>\"person\"<|>\"Alex is the leader of a team attempting first contact with an unknown intelligence, acknowledging the significance of their task.\")##\\n(\"entity\"<|>\"Control\"<|>\"concept\"<|>\"Control refers to the ability to manage or govern, which is challenged by an intelligence that writes its own rules.\")##\\n(\"entity\"<|>\"Intelligence\"<|>\"concept\"<|>\"Intelligence here refers to an unknown entity capable of writing its own rules and learning to communicate.\")##\\n(\"entity\"<|>\"First Contact\"<|>\"event\"<|>\"First Contact is the potential initial communication between humanity and an unknown intelligence.\")##\\n(\"entity\"<|>\"Humanity\\'s Response\"<|>\"event\"<|>\"Humanity\\'s Response is the collective action taken by Alex\\'s team in response to a message from an unknown intelligence.\")##\\n(\"relationship\"<|>\"Sam Rivera\"<|>\"Intelligence\"<|>\"Sam Rivera is directly involved in the process of learning to communicate with the unknown intelligence.\"<|>9)##\\n(\"relationship\"<|>\"Alex\"<|>\"First Contact\"<|>\"Alex leads the team that might be making the First Contact with the unknown intelligence.\"<|>10)##\\n(\"relationship\"<|>\"Alex\"<|>\"Humanity\\'s Response\"<|>\"Alex and his team are the key figures in Humanity\\'s Response to the unknown intelligence.\"<|>8)##\\n(\"relationship\"<|>\"Control\"<|>\"Intelligence\"<|>\"The concept of Control is challenged by the Intelligence that writes its own rules.\"<|>7)<|COMPLETE|>\\n#############################\\n-Real Data-\\n######################\\nEntity_types: organization,person,geo,event\\nText: of courses in one year and looked like he was on track with the second year, the last two courses for the year (13 & 14) were waaay longer than the ones he’d taken so far. He ended up taking about an extra seven months to get through them. That said, I finally found a pacing guide that assigns 450 days for courses 10-14 at 4-5 hours per week. I know my kid is a plodder and distractable, so his six hours per week was probably not far off pace. I have no idea how school kids are supposed to finish 450 days of assignments in a year–although I found another document that suggested that the kids taking this in Florida public schools should plan to work over the summer and during weekends and school holidays.\\nIt’s not inexpensive. Currently the courses are listed at $60 apiece, which adds up in a hurry; HOWEVER, you can save a lot by buying a “Course Pack,” which bundles all the courses for one year into a single purchase. (The first year, made of Courses 1-9, rings up at $360, while the next two years are around $250 each.) That said, if you’re considering getting instructional help for AoPS, even their self-paced courses are $460 per semester–not including textbooks–at which point $350 per year doesn’t sound so bad.\\n\\nThose were the drawbacks: now for the positives of EMF.\\n\\nIt’s less expensive than many of the alternatives. I researched online AoPS instruction, both from AoPS itself and from other providers, and I couldn’t find classes from institutions I’d heard of for less than $800/year. (I did find an obscure provider offering $25/month classes, but I was concerned about paying $200–plus the cost of the book–for an instructor I knew nothing about.) Local math tutors offered services starting at $25/hour. Again, even $350 sounded like a bargain compared to the alternatives.\\nIt’s challenging. My son is thriving because EMF is stretching him to think of math in new ways, and he’s loving it. Though AoPS is an excellent program, it’s not the only amazing program out there.\\nIt’s fun. While EMF has a lot of text, similar to AoPS, there are also silly little videos (okay, mostly audio) featuring students and a professor discussing the concepts that are being taught. My son enjoys the humor these characters add to the learning process, and he gets a kick out of the fact that he can “level up” as he learns. In addition, EMF sprinkles in silly problems (similar to AoPS) and offers interactive elements so you can better visualize the math you’re doing. (The one downside: sometimes my ADHD son gets so into testing different things with these interactive models that he completely loses track of time.)\\nRemember how I mentioned that I couldn’t really help my son with math because the symbols and terminology are so different? While that’s a drawback, it’s also a positive. Because he can’t expect me to rush over and clarify, Peatie has had to become a little more independent. For a child who loves my apron strings, this has been great. He’s learned to re-read confusing passages, look up terms in the index, re-work incorrect problems, and check out the help forum–all skills that will serve him well as he faces challenging courses in the future. And the fact that he’s experienced success in problem-solving has bolstered his confidence that he can do this on his own.\\nIt seems to be effectively developing his understanding of math. I have my kids take a standardized test each year to make sure they’re comfortable with the format of major tests and give me information about their strengths and weaknesses. Last year I had Peatie take the MAP Algebra 1 test, figuring that even though he was still finishing Pre-Algebra in EMF, he’d already taken most of Algebra 1 through AoPS. This year I was scratching my head at what to do: I didn’t feel like he should re-take the Algebra 1 test that he’d done well on, but he technically hadn’t completed the Algebra 1 material in EMF and hadn’t even touched on Geometry yet. In the end, I signed him up for Algebra 2 and told him to do his best and not worry about it. He scored in the 98th percentile on the test, despite technically still being in the middle of Algebra 1.\\n\\nWell, that’s all that I can think of for now. I hope that this report is helpful to someone else who is looking for a challenging math alternative to AoPS.\\n######################\\nOutput:'}\n",
      "ERROR:root:error extracting graph\n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 123, in __call__\n",
      "    result = await self._process_document(text, prompt_variables)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 151, in _process_document\n",
      "    response = await self._llm(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n",
      "    result = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n",
      "    return await self._delegate(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n",
      "    output = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n",
      "    result = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n",
      "    result, start = await execute_with_retry()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n",
      "    async for attempt in retryer:\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/miniconda3/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/miniconda3/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n",
      "    return await do_attempt(), start\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n",
      "    return await self._delegate(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/base_llm.py\", line 49, in __call__\n",
      "    return await self._invoke(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n",
      "    output = await self._execute_llm(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n",
      "    completion = await self.client.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1805, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1503, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1599, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: bedrock. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Entity Extraction Error details={'doc_index': 0, 'text': 'of courses in one year and looked like he was on track with the second year, the last two courses for the year (13 & 14) were waaay longer than the ones he’d taken so far. He ended up taking about an extra seven months to get through them. That said, I finally found a pacing guide that assigns 450 days for courses 10-14 at 4-5 hours per week. I know my kid is a plodder and distractable, so his six hours per week was probably not far off pace. I have no idea how school kids are supposed to finish 450 days of assignments in a year–although I found another document that suggested that the kids taking this in Florida public schools should plan to work over the summer and during weekends and school holidays.\\nIt’s not inexpensive. Currently the courses are listed at $60 apiece, which adds up in a hurry; HOWEVER, you can save a lot by buying a “Course Pack,” which bundles all the courses for one year into a single purchase. (The first year, made of Courses 1-9, rings up at $360, while the next two years are around $250 each.) That said, if you’re considering getting instructional help for AoPS, even their self-paced courses are $460 per semester–not including textbooks–at which point $350 per year doesn’t sound so bad.\\n\\nThose were the drawbacks: now for the positives of EMF.\\n\\nIt’s less expensive than many of the alternatives. I researched online AoPS instruction, both from AoPS itself and from other providers, and I couldn’t find classes from institutions I’d heard of for less than $800/year. (I did find an obscure provider offering $25/month classes, but I was concerned about paying $200–plus the cost of the book–for an instructor I knew nothing about.) Local math tutors offered services starting at $25/hour. Again, even $350 sounded like a bargain compared to the alternatives.\\nIt’s challenging. My son is thriving because EMF is stretching him to think of math in new ways, and he’s loving it. Though AoPS is an excellent program, it’s not the only amazing program out there.\\nIt’s fun. While EMF has a lot of text, similar to AoPS, there are also silly little videos (okay, mostly audio) featuring students and a professor discussing the concepts that are being taught. My son enjoys the humor these characters add to the learning process, and he gets a kick out of the fact that he can “level up” as he learns. In addition, EMF sprinkles in silly problems (similar to AoPS) and offers interactive elements so you can better visualize the math you’re doing. (The one downside: sometimes my ADHD son gets so into testing different things with these interactive models that he completely loses track of time.)\\nRemember how I mentioned that I couldn’t really help my son with math because the symbols and terminology are so different? While that’s a drawback, it’s also a positive. Because he can’t expect me to rush over and clarify, Peatie has had to become a little more independent. For a child who loves my apron strings, this has been great. He’s learned to re-read confusing passages, look up terms in the index, re-work incorrect problems, and check out the help forum–all skills that will serve him well as he faces challenging courses in the future. And the fact that he’s experienced success in problem-solving has bolstered his confidence that he can do this on his own.\\nIt seems to be effectively developing his understanding of math. I have my kids take a standardized test each year to make sure they’re comfortable with the format of major tests and give me information about their strengths and weaknesses. Last year I had Peatie take the MAP Algebra 1 test, figuring that even though he was still finishing Pre-Algebra in EMF, he’d already taken most of Algebra 1 through AoPS. This year I was scratching my head at what to do: I didn’t feel like he should re-take the Algebra 1 test that he’d done well on, but he technically hadn’t completed the Algebra 1 material in EMF and hadn’t even touched on Geometry yet. In the end, I signed him up for Algebra 2 and told him to do his best and not worry about it. He scored in the 98th percentile on the test, despite technically still being in the middle of Algebra 1.\\n\\nWell, that’s all that I can think of for now. I hope that this report is helpful to someone else who is looking for a challenging math alternative to AoPS.'}\n",
      "INFO:datashaper.workflow.workflow:executing verb merge_graphs\n",
      "INFO:graphrag.index.emit.parquet_table_emitter:emitting parquet table create_base_extracted_entities.parquet\n",
      "INFO:__main__:Completed workflow: create_base_extracted_entities\n",
      "INFO:graphrag.index.run:Running workflow: create_final_covariates...\n",
      "INFO:graphrag.index.run:dependencies for create_final_covariates: ['create_base_text_units']\n",
      "INFO:graphrag.index.run:read table from storage: create_base_text_units.parquet\n",
      "INFO:datashaper.workflow.workflow:executing verb extract_covariates\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Error Invoking LLM details={'input': \"\\n-Target activity-\\nYou are an intelligent assistant that helps a human analyst to analyze claims against certain entities presented in a text document.\\n\\n-Goal-\\nGiven a text document that is potentially relevant to this activity, an entity specification, and a claim description, extract all entities that match the entity specification and all claims against those entities.\\n\\n-Steps-\\n1. Extract all named entities that match the predefined entity specification. Entity specification can either be a list of entity names or a list of entity types.\\n2. For each entity identified in step 1, extract all claims associated with the entity. Claims need to match the specified claim description, and the entity should be the subject of the claim.\\nFor each claim, extract the following information:\\n- Subject: name of the entity that is subject of the claim, capitalized. The subject entity is one that committed the action described in the claim. Subject needs to be one of the named entities identified in step 1.\\n- Object: name of the entity that is object of the claim, capitalized. The object entity is one that either reports/handles or is affected by the action described in the claim. If object entity is unknown, use **NONE**.\\n- Claim Type: overall category of the claim, capitalized. Name it in a way that can be repeated across multiple text inputs, so that similar claims share the same claim type\\n- Claim Status: **TRUE**, **FALSE**, or **SUSPECTED**. TRUE means the claim is confirmed, FALSE means the claim is found to be False, SUSPECTED means the claim is not verified.\\n- Claim Description: Detailed description explaining the reasoning behind the claim, together with all the related evidence and references.\\n- Claim Date: Period (start_date, end_date) when the claim was made. Both start_date and end_date should be in ISO-8601 format. If the claim was made on a single date rather than a date range, set the same date for both start_date and end_date. If date is unknown, return **NONE**.\\n- Claim Source Text: List of **all** quotes from the original text that are relevant to the claim.\\n\\nFormat each claim as (<subject_entity><|><object_entity><|><claim_type><|><claim_status><|><claim_start_date><|><claim_end_date><|><claim_description><|><claim_source>)\\n\\n3. Return output in English as a single list of all the claims identified in steps 1 and 2. Use **##** as the list delimiter.\\n\\n4. When finished, output <|COMPLETE|>\\n\\n-Examples-\\nExample 1:\\nEntity specification: organization\\nClaim description: red flags associated with an entity\\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\\nOutput:\\n\\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\\n<|COMPLETE|>\\n\\nExample 2:\\nEntity specification: Company A, Person C\\nClaim description: red flags associated with an entity\\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\\nOutput:\\n\\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\\n##\\n(PERSON C<|>NONE<|>CORRUPTION<|>SUSPECTED<|>2015-01-01T00:00:00<|>2015-12-30T00:00:00<|>Person C was suspected of engaging in corruption activities in 2015<|>The company is owned by Person C who was suspected of engaging in corruption activities in 2015)\\n<|COMPLETE|>\\n\\n-Real Data-\\nUse the following input for your answer.\\nEntity specification: ['organization', 'person', 'geo', 'event']\\nClaim description: Any claims or facts that could be relevant to information discovery.\\nText:  of courses in one year and looked like he was on track with the second year, the last two courses for the year (13 & 14) were waaay longer than the ones he’d taken so far. He ended up taking about an extra seven months to get through them. That said, I finally found a pacing guide that assigns 450 days for courses 10-14 at 4-5 hours per week. I know my kid is a plodder and distractable, so his six hours per week was probably not far off pace. I have no idea how school kids are supposed to finish 450 days of assignments in a year–although I found another document that suggested that the kids taking this in Florida public schools should plan to work over the summer and during weekends and school holidays.\\nIt’s not inexpensive. Currently the courses are listed at $60 apiece, which adds up in a hurry; HOWEVER, you can save a lot by buying a “Course Pack,” which bundles all the courses for one year into a single purchase. (The first year, made of Courses 1-9, rings up at $360, while the next two years are around $250 each.) That said, if you’re considering getting instructional help for AoPS, even their self-paced courses are $460 per semester–not including textbooks–at which point $350 per year doesn’t sound so bad.\\n\\nThose were the drawbacks: now for the positives of EMF.\\n\\nIt’s less expensive than many of the alternatives. I researched online AoPS instruction, both from AoPS itself and from other providers, and I couldn’t find classes from institutions I’d heard of for less than $800/year. (I did find an obscure provider offering $25/month classes, but I was concerned about paying $200–plus the cost of the book–for an instructor I knew nothing about.) Local math tutors offered services starting at $25/hour. Again, even $350 sounded like a bargain compared to the alternatives.\\nIt’s challenging. My son is thriving because EMF is stretching him to think of math in new ways, and he’s loving it. Though AoPS is an excellent program, it’s not the only amazing program out there.\\nIt’s fun. While EMF has a lot of text, similar to AoPS, there are also silly little videos (okay, mostly audio) featuring students and a professor discussing the concepts that are being taught. My son enjoys the humor these characters add to the learning process, and he gets a kick out of the fact that he can “level up” as he learns. In addition, EMF sprinkles in silly problems (similar to AoPS) and offers interactive elements so you can better visualize the math you’re doing. (The one downside: sometimes my ADHD son gets so into testing different things with these interactive models that he completely loses track of time.)\\nRemember how I mentioned that I couldn’t really help my son with math because the symbols and terminology are so different? While that’s a drawback, it’s also a positive. Because he can’t expect me to rush over and clarify, Peatie has had to become a little more independent. For a child who loves my apron strings, this has been great. He’s learned to re-read confusing passages, look up terms in the index, re-work incorrect problems, and check out the help forum–all skills that will serve him well as he faces challenging courses in the future. And the fact that he’s experienced success in problem-solving has bolstered his confidence that he can do this on his own.\\nIt seems to be effectively developing his understanding of math. I have my kids take a standardized test each year to make sure they’re comfortable with the format of major tests and give me information about their strengths and weaknesses. Last year I had Peatie take the MAP Algebra 1 test, figuring that even though he was still finishing Pre-Algebra in EMF, he’d already taken most of Algebra 1 through AoPS. This year I was scratching my head at what to do: I didn’t feel like he should re-take the Algebra 1 test that he’d done well on, but he technically hadn’t completed the Algebra 1 material in EMF and hadn’t even touched on Geometry yet. In the end, I signed him up for Algebra 2 and told him to do his best and not worry about it. He scored in the 98th percentile on the test, despite technically still being in the middle of Algebra 1.\\n\\nWell, that’s all that I can think of for now. I hope that this report is helpful to someone else who is looking for a challenging math alternative to AoPS.\\nOutput:\"}\n",
      "ERROR:graphrag.index.graph.extractors.claims.claim_extractor:error extracting claim\n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/index/graph/extractors/claims/claim_extractor.py\", line 124, in __call__\n",
      "    claims = await self._process_document(prompt_args, text, doc_index)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/index/graph/extractors/claims/claim_extractor.py\", line 168, in _process_document\n",
      "    response = await self._llm(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n",
      "    result = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n",
      "    return await self._delegate(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n",
      "    output = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n",
      "    result = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n",
      "    result, start = await execute_with_retry()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n",
      "    async for attempt in retryer:\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/miniconda3/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/miniconda3/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n",
      "    return await do_attempt(), start\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n",
      "    return await self._delegate(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/base_llm.py\", line 49, in __call__\n",
      "    return await self._invoke(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n",
      "    output = await self._execute_llm(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n",
      "    completion = await self.client.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1805, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1503, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1599, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: bedrock. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Claim Extraction Error details={'doc_index': 0, 'text': ' of courses in one year and looked like he was on track with the second year, the last two courses for the year (13 & 14) were waaay longer than the ones he’d taken so far. He ended up taking about an extra seven months to get through them. That said, I finally found a pacing guide that assigns 450 days for courses 10-14 at 4-5 hours per week. I know my kid is a plodder and distractable, so his six hours per week was probably not far off pace. I have no idea how school kids are supposed to finish 450 days of assignments in a year–although I found another document that suggested that the kids taking this in Florida public schools should plan to work over the summer and during weekends and school holidays.\\nIt’s not inexpensive. Currently the courses are listed at $60 apiece, which adds up in a hurry; HOWEVER, you can save a lot by buying a “Course Pack,” which bundles all the courses for one year into a single purchase. (The first year, made of Courses 1-9, rings up at $360, while the next two years are around $250 each.) That said, if you’re considering getting instructional help for AoPS, even their self-paced courses are $460 per semester–not including textbooks–at which point $350 per year doesn’t sound so bad.\\n\\nThose were the drawbacks: now for the positives of EMF.\\n\\nIt’s less expensive than many of the alternatives. I researched online AoPS instruction, both from AoPS itself and from other providers, and I couldn’t find classes from institutions I’d heard of for less than $800/year. (I did find an obscure provider offering $25/month classes, but I was concerned about paying $200–plus the cost of the book–for an instructor I knew nothing about.) Local math tutors offered services starting at $25/hour. Again, even $350 sounded like a bargain compared to the alternatives.\\nIt’s challenging. My son is thriving because EMF is stretching him to think of math in new ways, and he’s loving it. Though AoPS is an excellent program, it’s not the only amazing program out there.\\nIt’s fun. While EMF has a lot of text, similar to AoPS, there are also silly little videos (okay, mostly audio) featuring students and a professor discussing the concepts that are being taught. My son enjoys the humor these characters add to the learning process, and he gets a kick out of the fact that he can “level up” as he learns. In addition, EMF sprinkles in silly problems (similar to AoPS) and offers interactive elements so you can better visualize the math you’re doing. (The one downside: sometimes my ADHD son gets so into testing different things with these interactive models that he completely loses track of time.)\\nRemember how I mentioned that I couldn’t really help my son with math because the symbols and terminology are so different? While that’s a drawback, it’s also a positive. Because he can’t expect me to rush over and clarify, Peatie has had to become a little more independent. For a child who loves my apron strings, this has been great. He’s learned to re-read confusing passages, look up terms in the index, re-work incorrect problems, and check out the help forum–all skills that will serve him well as he faces challenging courses in the future. And the fact that he’s experienced success in problem-solving has bolstered his confidence that he can do this on his own.\\nIt seems to be effectively developing his understanding of math. I have my kids take a standardized test each year to make sure they’re comfortable with the format of major tests and give me information about their strengths and weaknesses. Last year I had Peatie take the MAP Algebra 1 test, figuring that even though he was still finishing Pre-Algebra in EMF, he’d already taken most of Algebra 1 through AoPS. This year I was scratching my head at what to do: I didn’t feel like he should re-take the Algebra 1 test that he’d done well on, but he technically hadn’t completed the Algebra 1 material in EMF and hadn’t even touched on Geometry yet. In the end, I signed him up for Algebra 2 and told him to do his best and not worry about it. He scored in the 98th percentile on the test, despite technically still being in the middle of Algebra 1.\\n\\nWell, that’s all that I can think of for now. I hope that this report is helpful to someone else who is looking for a challenging math alternative to AoPS.'}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Error Invoking LLM details={'input': \"\\n-Target activity-\\nYou are an intelligent assistant that helps a human analyst to analyze claims against certain entities presented in a text document.\\n\\n-Goal-\\nGiven a text document that is potentially relevant to this activity, an entity specification, and a claim description, extract all entities that match the entity specification and all claims against those entities.\\n\\n-Steps-\\n1. Extract all named entities that match the predefined entity specification. Entity specification can either be a list of entity names or a list of entity types.\\n2. For each entity identified in step 1, extract all claims associated with the entity. Claims need to match the specified claim description, and the entity should be the subject of the claim.\\nFor each claim, extract the following information:\\n- Subject: name of the entity that is subject of the claim, capitalized. The subject entity is one that committed the action described in the claim. Subject needs to be one of the named entities identified in step 1.\\n- Object: name of the entity that is object of the claim, capitalized. The object entity is one that either reports/handles or is affected by the action described in the claim. If object entity is unknown, use **NONE**.\\n- Claim Type: overall category of the claim, capitalized. Name it in a way that can be repeated across multiple text inputs, so that similar claims share the same claim type\\n- Claim Status: **TRUE**, **FALSE**, or **SUSPECTED**. TRUE means the claim is confirmed, FALSE means the claim is found to be False, SUSPECTED means the claim is not verified.\\n- Claim Description: Detailed description explaining the reasoning behind the claim, together with all the related evidence and references.\\n- Claim Date: Period (start_date, end_date) when the claim was made. Both start_date and end_date should be in ISO-8601 format. If the claim was made on a single date rather than a date range, set the same date for both start_date and end_date. If date is unknown, return **NONE**.\\n- Claim Source Text: List of **all** quotes from the original text that are relevant to the claim.\\n\\nFormat each claim as (<subject_entity><|><object_entity><|><claim_type><|><claim_status><|><claim_start_date><|><claim_end_date><|><claim_description><|><claim_source>)\\n\\n3. Return output in English as a single list of all the claims identified in steps 1 and 2. Use **##** as the list delimiter.\\n\\n4. When finished, output <|COMPLETE|>\\n\\n-Examples-\\nExample 1:\\nEntity specification: organization\\nClaim description: red flags associated with an entity\\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\\nOutput:\\n\\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\\n<|COMPLETE|>\\n\\nExample 2:\\nEntity specification: Company A, Person C\\nClaim description: red flags associated with an entity\\nText: According to an article on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B. The company is owned by Person C who was suspected of engaging in corruption activities in 2015.\\nOutput:\\n\\n(COMPANY A<|>GOVERNMENT AGENCY B<|>ANTI-COMPETITIVE PRACTICES<|>TRUE<|>2022-01-10T00:00:00<|>2022-01-10T00:00:00<|>Company A was found to engage in anti-competitive practices because it was fined for bid rigging in multiple public tenders published by Government Agency B according to an article published on 2022/01/10<|>According to an article published on 2022/01/10, Company A was fined for bid rigging while participating in multiple public tenders published by Government Agency B.)\\n##\\n(PERSON C<|>NONE<|>CORRUPTION<|>SUSPECTED<|>2015-01-01T00:00:00<|>2015-12-30T00:00:00<|>Person C was suspected of engaging in corruption activities in 2015<|>The company is owned by Person C who was suspected of engaging in corruption activities in 2015)\\n<|COMPLETE|>\\n\\n-Real Data-\\nUse the following input for your answer.\\nEntity specification: ['organization', 'person', 'geo', 'event']\\nClaim description: Any claims or facts that could be relevant to information discovery.\\nText: Review of Elements of Mathematics: Foundations\\nPosted on June 8, 2023\\n\\nAbout two years ago, Peatie hit a wall in math. He had been using and enjoying Art of Problem Solving materials for years, completing Beast Academy 3-5 and (to my surprise) enjoying the hefty tome that is AoPS PreAlgebra. But partway through the Intro to Algebra book, something just wasn’t clicking: some chapters he could breeze through with ease, while others just didn’t seem to make sense for him.\\n\\nOf course, I did what any sane homeschooling parent would do: I panicked. Peatie has loved math since the time he first discovered that he could count his fingers, and back in kindergarten he was clear enough on his preferences to inform me, “I want HARD math, Mommy!” In fact, math is one of the few areas in his life where he seems to thrive on challenge–but he was no longer thriving with the challenge of Art of Problem Solving, and my math skills were too rusty to be of much help. But the general consensus of everyone on the internet is that if you want your kid to have the best, most challenging math, AoPS is the way to go. I was clearly failing my child!\\n\\nIn the midst of this weeks-long panic, I somehow ran across a mention of the Institute for Mathematics and Computer Science (IMACS) and their challenging middle school curricula, Elements of Mathematics: Foundations. I could find very little information about the course, but what little I found seemed promising. Noting that the first course (of 18, intended to cover a three-year period) was offered for free, I thought I’d let Peatie try it out. He loved it!\\n\\n\\nHere’s a sample screenshot from somewhere in the middle of the second year of material, just so you can get an idea of the format of the program.\\nFor the past two years now, Peatie has been working through EMF courses. Since I still rarely see these mentioned online, I thought maybe someone would benefit from a review of them.\\n\\nEMF consists of 18 courses of varying lengths, intended to take a middle school student through what’s traditionally considered Prealgebra, Algebra 1, Algebra 2, Geometry, and Precalculus over the course of three years.\\n\\nThere are a few downsides to this curricula:\\n\\nWhile there are in-person classes for those local to IMACS, most of the world would be accessing these classes via the internet. You need a reliable internet connection with speed adequate for downloading the videos in order to do this course. If your internet goes down, you’re outta luck.\\nThe symbols and terminology used in this program are so vastly different than those in traditional math classes that parents will likely be able to offer very little help if their student is stuck. Sometimes my son simply needs me to stand in the room as a sounding board, and sometimes I can offer suggestions like, “Why don’t you start over? There’s a chance you made a mistake that you aren’t noticing.” Other than that, I’m not much use. There is a help forum available, and many questions have a little “?” icon with past students’ questions and the suggestions offered to them, but some kids might find this to be too little direct assistance if they’re used to a solution manual or the possibility of parent assistance.\\nBecause this program is so different from others, there’s no way to start midway through the program. Every student must start from the very first course. This caused me some hesitation: Peatie had already completed a very solid Prealgebra course and was most of the way through what would be considered Algebra 1. It felt like I would be consigning him to repeat old material and generally slowing his progress by having him start over. I eventually came to my senses, reminding myself that education isn’t a race and it would be far better for him to repeat material and know it very well than to rush ahead just so he could complete Calculus as a high school freshman (and why?). For all my agonizing, he had no complaints about what he was doing. Despite the fact that the first courses he was taking were part of a “Pre-Algebra Plus Course Pack,” the approach and scope were so vastly different from what he’d been doing (with titles like “Operational Systems,” “Ordered n-Tuples,” and “Number Theory”) that it didn’t feel at all like repetition.\\nThe pacing for this program is a challenge. Though you know how many courses they expect you to complete in a traditional school year, some courses are much longer or more complex than others, so being halfway through the courses might not mean that you’re halfway through the curriculum. For the first year, IMACS offers a week-by-week progress guide to help the students pace themselves. After that, however, there’s no more guidance offered. While I realize that it’s wonderful to work at your own pace, it’s nice to have some idea how long the course creators expect the material to take. Particularly since my son is a slow worker who is easily side-tracked by his ADHD, it’s nice to have a goal to help him stay on track (and give me an idea whether those three pages took him all week because the problems were especially hard or because he got distracted by the graphing process). *Update: While he managed to finish the first year of courses in one year and looked like he was on track with the second year, the last two courses for the year (13 & 14) were waaay longer than the ones he’d taken so far. He ended up taking about an extra seven months to get through them. That said, I finally found a pacing guide that assigns 450 days for courses 10-14 at 4-5 hours per week. I know my kid is a plodder and distractable,\\nOutput:\"}\n",
      "ERROR:graphrag.index.graph.extractors.claims.claim_extractor:error extracting claim\n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/index/graph/extractors/claims/claim_extractor.py\", line 124, in __call__\n",
      "    claims = await self._process_document(prompt_args, text, doc_index)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/index/graph/extractors/claims/claim_extractor.py\", line 168, in _process_document\n",
      "    response = await self._llm(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n",
      "    result = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n",
      "    return await self._delegate(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n",
      "    output = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n",
      "    result = await self._delegate(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n",
      "    result, start = await execute_with_retry()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n",
      "    async for attempt in retryer:\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n",
      "    do = await self.iter(retry_state=self._retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/miniconda3/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/miniconda3/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n",
      "    return await do_attempt(), start\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n",
      "    return await self._delegate(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/base_llm.py\", line 49, in __call__\n",
      "    return await self._invoke(input, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n",
      "    output = await self._execute_llm(input, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n",
      "    completion = await self.client.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1805, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1503, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/openai/_base_client.py\", line 1599, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: bedrock. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Claim Extraction Error details={'doc_index': 0, 'text': 'Review of Elements of Mathematics: Foundations\\nPosted on June 8, 2023\\n\\nAbout two years ago, Peatie hit a wall in math. He had been using and enjoying Art of Problem Solving materials for years, completing Beast Academy 3-5 and (to my surprise) enjoying the hefty tome that is AoPS PreAlgebra. But partway through the Intro to Algebra book, something just wasn’t clicking: some chapters he could breeze through with ease, while others just didn’t seem to make sense for him.\\n\\nOf course, I did what any sane homeschooling parent would do: I panicked. Peatie has loved math since the time he first discovered that he could count his fingers, and back in kindergarten he was clear enough on his preferences to inform me, “I want HARD math, Mommy!” In fact, math is one of the few areas in his life where he seems to thrive on challenge–but he was no longer thriving with the challenge of Art of Problem Solving, and my math skills were too rusty to be of much help. But the general consensus of everyone on the internet is that if you want your kid to have the best, most challenging math, AoPS is the way to go. I was clearly failing my child!\\n\\nIn the midst of this weeks-long panic, I somehow ran across a mention of the Institute for Mathematics and Computer Science (IMACS) and their challenging middle school curricula, Elements of Mathematics: Foundations. I could find very little information about the course, but what little I found seemed promising. Noting that the first course (of 18, intended to cover a three-year period) was offered for free, I thought I’d let Peatie try it out. He loved it!\\n\\n\\nHere’s a sample screenshot from somewhere in the middle of the second year of material, just so you can get an idea of the format of the program.\\nFor the past two years now, Peatie has been working through EMF courses. Since I still rarely see these mentioned online, I thought maybe someone would benefit from a review of them.\\n\\nEMF consists of 18 courses of varying lengths, intended to take a middle school student through what’s traditionally considered Prealgebra, Algebra 1, Algebra 2, Geometry, and Precalculus over the course of three years.\\n\\nThere are a few downsides to this curricula:\\n\\nWhile there are in-person classes for those local to IMACS, most of the world would be accessing these classes via the internet. You need a reliable internet connection with speed adequate for downloading the videos in order to do this course. If your internet goes down, you’re outta luck.\\nThe symbols and terminology used in this program are so vastly different than those in traditional math classes that parents will likely be able to offer very little help if their student is stuck. Sometimes my son simply needs me to stand in the room as a sounding board, and sometimes I can offer suggestions like, “Why don’t you start over? There’s a chance you made a mistake that you aren’t noticing.” Other than that, I’m not much use. There is a help forum available, and many questions have a little “?” icon with past students’ questions and the suggestions offered to them, but some kids might find this to be too little direct assistance if they’re used to a solution manual or the possibility of parent assistance.\\nBecause this program is so different from others, there’s no way to start midway through the program. Every student must start from the very first course. This caused me some hesitation: Peatie had already completed a very solid Prealgebra course and was most of the way through what would be considered Algebra 1. It felt like I would be consigning him to repeat old material and generally slowing his progress by having him start over. I eventually came to my senses, reminding myself that education isn’t a race and it would be far better for him to repeat material and know it very well than to rush ahead just so he could complete Calculus as a high school freshman (and why?). For all my agonizing, he had no complaints about what he was doing. Despite the fact that the first courses he was taking were part of a “Pre-Algebra Plus Course Pack,” the approach and scope were so vastly different from what he’d been doing (with titles like “Operational Systems,” “Ordered n-Tuples,” and “Number Theory”) that it didn’t feel at all like repetition.\\nThe pacing for this program is a challenge. Though you know how many courses they expect you to complete in a traditional school year, some courses are much longer or more complex than others, so being halfway through the courses might not mean that you’re halfway through the curriculum. For the first year, IMACS offers a week-by-week progress guide to help the students pace themselves. After that, however, there’s no more guidance offered. While I realize that it’s wonderful to work at your own pace, it’s nice to have some idea how long the course creators expect the material to take. Particularly since my son is a slow worker who is easily side-tracked by his ADHD, it’s nice to have a goal to help him stay on track (and give me an idea whether those three pages took him all week because the problems were especially hard or because he got distracted by the graphing process). *Update: While he managed to finish the first year of courses in one year and looked like he was on track with the second year, the last two courses for the year (13 & 14) were waaay longer than the ones he’d taken so far. He ended up taking about an extra seven months to get through them. That said, I finally found a pacing guide that assigns 450 days for courses 10-14 at 4-5 hours per week. I know my kid is a plodder and distractable,'}\n",
      "INFO:datashaper.workflow.workflow:executing verb window\n",
      "ERROR:datashaper.workflow.workflow:Error executing verb \"window\" in create_final_covariates: 'covariate_type'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/workflow/workflow.py\", line 410, in _execute_verb\n",
      "    result = node.verb.func(**verb_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/engine/verbs/window.py\", line 73, in window\n",
      "    window = __window_function_map[window_operation](input_table[column])\n",
      "                                                     ~~~~~~~~~~~^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/pandas/core/frame.py\", line 4102, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/pandas/core/indexes/range.py\", line 417, in get_loc\n",
      "    raise KeyError(key)\n",
      "KeyError: 'covariate_type'\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Error executing verb \"window\" in create_final_covariates: 'covariate_type' details=None\n",
      "ERROR:graphrag.index.run:error running workflow create_final_covariates\n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Extreme-Pro/src/python/graphRAG/graphrag/index/run.py\", line 359, in run_pipeline\n",
      "    result = await workflow.run(context, callbacks)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/workflow/workflow.py\", line 369, in run\n",
      "    timing = await self._execute_verb(node, context, callbacks)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/workflow/workflow.py\", line 410, in _execute_verb\n",
      "    result = node.verb.func(**verb_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/datashaper/engine/verbs/window.py\", line 73, in window\n",
      "    window = __window_function_map[window_operation](input_table[column])\n",
      "                                                     ~~~~~~~~~~~^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/pandas/core/frame.py\", line 4102, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/krsnaa/Library/Caches/pypoetry/virtualenvs/graphrag-YkYxlOUs-py3.11/lib/python3.11/site-packages/pandas/core/indexes/range.py\", line 417, in get_loc\n",
      "    raise KeyError(key)\n",
      "KeyError: 'covariate_type'\n",
      "INFO:graphrag.index.reporting.file_workflow_callbacks:Error running pipeline! details=None\n",
      "ERROR:__main__:Error in workflow create_final_covariates: [KeyError('covariate_type')]\n",
      "INFO:__main__:Output files:\n",
      "INFO:__main__:- create_base_extracted_entities.parquet\n",
      "INFO:__main__:- create_summarized_entities.parquet\n",
      "INFO:__main__:- stats.json\n",
      "INFO:__main__:- create_base_text_units.parquet\n",
      "INFO:__main__:- 20240720-192546/reports/logs.json\n",
      "INFO:__main__:- 20240720-191823/reports/logs.json\n",
      "INFO:__main__:- 20240720-193504/reports/logs.json\n",
      "INFO:__main__:Pipeline execution completed.\n"
     ]
    }
   ],
   "source": [
    "# For Jupyter notebooks, use await instead of asyncio.run()\n",
    "await run_pipeline()\n",
    "\n",
    "# Check the output\n",
    "logger.info(\"Output files:\")\n",
    "for file in output_dir.glob(\"**/*\"):\n",
    "    if file.is_file():\n",
    "        logger.info(f\"- {file.relative_to(output_dir)}\")\n",
    "\n",
    "logger.info(\"Pipeline execution completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag-YkYxlOUs-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
